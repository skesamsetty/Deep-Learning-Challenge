{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charity Funding Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# tf.keras.callbacks.ModelCheckpoint\n",
    "\n",
    "#  read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"../Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "df = application_df.drop(columns = ['EIN', 'NAME'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T25        3\n",
       "T14        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T9', 'T13', 'T12', 'T2', 'T25', 'T14', 'T29', 'T15', 'T17']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = df['APPLICATION_TYPE'].value_counts() \\\n",
    "                                                        .loc[lambda x : x < 500] \\\n",
    "                                                        .index \\\n",
    "                                                        .to_list()\n",
    "application_types_to_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    df['APPLICATION_TYPE'] = df['APPLICATION_TYPE'].replace(app,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure binning was successful\n",
    "df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C4120        1\n",
       "C8210        1\n",
       "C2561        1\n",
       "C4500        1\n",
       "C2150        1\n",
       "Name: CLASSIFICATION, Length: 71, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C7200       32\n",
       "C2300       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1238       10\n",
       "C1278       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C2400        6\n",
       "C1720        6\n",
       "C4100        6\n",
       "C1257        5\n",
       "C1600        5\n",
       "C1260        3\n",
       "C2710        3\n",
       "C0           3\n",
       "C3200        2\n",
       "C1234        2\n",
       "C1246        2\n",
       "C1267        2\n",
       "C1256        2\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "df['CLASSIFICATION'].value_counts().loc[lambda x: x>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = df['CLASSIFICATION'].value_counts() \\\n",
    "                                                    .loc[lambda x : x < 1000] \\\n",
    "                                                    .index \\\n",
    "                                                    .to_list()\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    df['CLASSIFICATION'] = df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE             9\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION               6\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34294</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34295</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34296</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34297</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34298</th>\n",
       "      <td>1</td>\n",
       "      <td>36500179</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34299 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATUS   ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0           1      5000              1                       0   \n",
       "1           1    108590              1                       0   \n",
       "2           1      5000              0                       0   \n",
       "3           1      6692              1                       0   \n",
       "4           1    142590              1                       0   \n",
       "...       ...       ...            ...                     ...   \n",
       "34294       1      5000              0                       0   \n",
       "34295       1      5000              0                       0   \n",
       "34296       1      5000              0                       0   \n",
       "34297       1      5000              1                       0   \n",
       "34298       1  36500179              0                       0   \n",
       "\n",
       "       APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                         1                     0                    0   \n",
       "1                         0                     0                    1   \n",
       "2                         0                     0                    0   \n",
       "3                         0                     0                    1   \n",
       "4                         0                     0                    1   \n",
       "...                     ...                   ...                  ...   \n",
       "34294                     0                     0                    0   \n",
       "34295                     0                     0                    0   \n",
       "34296                     0                     0                    1   \n",
       "34297                     0                     0                    0   \n",
       "34298                     0                     0                    1   \n",
       "\n",
       "       APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  \\\n",
       "0                        0                    0                    0   \n",
       "1                        0                    0                    0   \n",
       "2                        0                    1                    0   \n",
       "3                        0                    0                    0   \n",
       "4                        0                    0                    0   \n",
       "...                    ...                  ...                  ...   \n",
       "34294                    1                    0                    0   \n",
       "34295                    1                    0                    0   \n",
       "34296                    0                    0                    0   \n",
       "34297                    0                    1                    0   \n",
       "34298                    0                    0                    0   \n",
       "\n",
       "       APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  AFFILIATION_CompanySponsored  \\\n",
       "0                        0                    0                             0   \n",
       "1                        0                    0                             0   \n",
       "2                        0                    0                             1   \n",
       "3                        0                    0                             1   \n",
       "4                        0                    0                             0   \n",
       "...                    ...                  ...                           ...   \n",
       "34294                    0                    0                             0   \n",
       "34295                    0                    0                             1   \n",
       "34296                    0                    0                             1   \n",
       "34297                    0                    0                             0   \n",
       "34298                    0                    0                             0   \n",
       "\n",
       "       AFFILIATION_Family/Parent  AFFILIATION_Independent  \\\n",
       "0                              0                        1   \n",
       "1                              0                        1   \n",
       "2                              0                        0   \n",
       "3                              0                        0   \n",
       "4                              0                        1   \n",
       "...                          ...                      ...   \n",
       "34294                          0                        1   \n",
       "34295                          0                        0   \n",
       "34296                          0                        0   \n",
       "34297                          0                        1   \n",
       "34298                          0                        1   \n",
       "\n",
       "       AFFILIATION_National  AFFILIATION_Other  AFFILIATION_Regional  \\\n",
       "0                         0                  0                     0   \n",
       "1                         0                  0                     0   \n",
       "2                         0                  0                     0   \n",
       "3                         0                  0                     0   \n",
       "4                         0                  0                     0   \n",
       "...                     ...                ...                   ...   \n",
       "34294                     0                  0                     0   \n",
       "34295                     0                  0                     0   \n",
       "34296                     0                  0                     0   \n",
       "34297                     0                  0                     0   \n",
       "34298                     0                  0                     0   \n",
       "\n",
       "       CLASSIFICATION_C1000  CLASSIFICATION_C1200  CLASSIFICATION_C2000  \\\n",
       "0                         1                     0                     0   \n",
       "1                         0                     0                     1   \n",
       "2                         0                     0                     0   \n",
       "3                         0                     0                     1   \n",
       "4                         1                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "34294                     1                     0                     0   \n",
       "34295                     0                     0                     0   \n",
       "34296                     0                     0                     1   \n",
       "34297                     0                     0                     0   \n",
       "34298                     1                     0                     0   \n",
       "\n",
       "       CLASSIFICATION_C2100  CLASSIFICATION_C3000  CLASSIFICATION_Other  \\\n",
       "0                         0                     0                     0   \n",
       "1                         0                     0                     0   \n",
       "2                         0                     1                     0   \n",
       "3                         0                     0                     0   \n",
       "4                         0                     0                     0   \n",
       "...                     ...                   ...                   ...   \n",
       "34294                     0                     0                     0   \n",
       "34295                     0                     1                     0   \n",
       "34296                     0                     0                     0   \n",
       "34297                     0                     1                     0   \n",
       "34298                     0                     0                     0   \n",
       "\n",
       "       USE_CASE_CommunityServ  USE_CASE_Heathcare  USE_CASE_Other  \\\n",
       "0                           0                   0               0   \n",
       "1                           0                   0               0   \n",
       "2                           0                   0               0   \n",
       "3                           0                   0               0   \n",
       "4                           0                   1               0   \n",
       "...                       ...                 ...             ...   \n",
       "34294                       0                   0               0   \n",
       "34295                       0                   0               0   \n",
       "34296                       0                   0               0   \n",
       "34297                       0                   0               0   \n",
       "34298                       0                   0               0   \n",
       "\n",
       "       USE_CASE_Preservation  USE_CASE_ProductDev  ORGANIZATION_Association  \\\n",
       "0                          0                    1                         1   \n",
       "1                          1                    0                         0   \n",
       "2                          0                    1                         1   \n",
       "3                          1                    0                         0   \n",
       "4                          0                    0                         0   \n",
       "...                      ...                  ...                       ...   \n",
       "34294                      0                    1                         1   \n",
       "34295                      0                    1                         1   \n",
       "34296                      1                    0                         1   \n",
       "34297                      0                    1                         1   \n",
       "34298                      1                    0                         0   \n",
       "\n",
       "       ORGANIZATION_Co-operative  ORGANIZATION_Corporation  \\\n",
       "0                              0                         0   \n",
       "1                              1                         0   \n",
       "2                              0                         0   \n",
       "3                              0                         0   \n",
       "4                              0                         0   \n",
       "...                          ...                       ...   \n",
       "34294                          0                         0   \n",
       "34295                          0                         0   \n",
       "34296                          0                         0   \n",
       "34297                          0                         0   \n",
       "34298                          1                         0   \n",
       "\n",
       "       ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
       "0                       0             1                  0   \n",
       "1                       0             0                  1   \n",
       "2                       0             1                  0   \n",
       "3                       1             0                  0   \n",
       "4                       1             0                  0   \n",
       "...                   ...           ...                ...   \n",
       "34294                   0             1                  0   \n",
       "34295                   0             1                  0   \n",
       "34296                   0             1                  0   \n",
       "34297                   0             1                  0   \n",
       "34298                   0             0                  0   \n",
       "\n",
       "       INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                           0                         0                   0   \n",
       "1                           0                         0                   0   \n",
       "2                           0                         0                   0   \n",
       "3                           1                         0                   0   \n",
       "4                           0                         1                   0   \n",
       "...                       ...                       ...                 ...   \n",
       "34294                       0                         0                   0   \n",
       "34295                       0                         0                   0   \n",
       "34296                       0                         0                   0   \n",
       "34297                       0                         0                   0   \n",
       "34298                       0                         0                   0   \n",
       "\n",
       "       INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0                     0                       0                0   \n",
       "1                     0                       0                0   \n",
       "2                     0                       0                0   \n",
       "3                     0                       0                0   \n",
       "4                     0                       0                0   \n",
       "...                 ...                     ...              ...   \n",
       "34294                 0                       0                0   \n",
       "34295                 0                       0                0   \n",
       "34296                 0                       0                0   \n",
       "34297                 0                       0                0   \n",
       "34298                 1                       0                0   \n",
       "\n",
       "       INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                      0                         1                         0  \n",
       "1                      0                         1                         0  \n",
       "2                      0                         1                         0  \n",
       "3                      0                         1                         0  \n",
       "4                      0                         1                         0  \n",
       "...                  ...                       ...                       ...  \n",
       "34294                  0                         1                         0  \n",
       "34295                  0                         1                         0  \n",
       "34296                  0                         1                         0  \n",
       "34297                  0                         1                         0  \n",
       "34298                  0                         1                         0  \n",
       "\n",
       "[34299 rows x 44 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "transformed_df = pd.get_dummies(df)\n",
    "transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "\n",
    "X = transformed_df.drop(columns = 'IS_SUCCESSFUL')\n",
    "y = transformed_df['IS_SUCCESSFUL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25724, 43), (8575, 43), (25724,), (8575,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the preprocessed data into a training and testing dataset\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 75)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                3520      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,981\n",
      "Trainable params: 5,981\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "\n",
    "nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=80, activation=\"relu\", input_dim=43))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=30, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x226e79772b0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile the model\n",
    "nn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "nn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "155/804 [====>.........................] - ETA: 0s - loss: 0.6023 - accuracy: 0.6907\n",
      "Epoch 00001: saving model to training\\cp-0001.ckpt\n",
      "287/804 [=========>....................] - ETA: 0s - loss: 0.5880 - accuracy: 0.7035\n",
      "Epoch 00001: saving model to training\\cp-0001.ckpt\n",
      "434/804 [===============>..............] - ETA: 0s - loss: 0.5781 - accuracy: 0.7127\n",
      "Epoch 00001: saving model to training\\cp-0001.ckpt\n",
      "570/804 [====================>.........] - ETA: 0s - loss: 0.5752 - accuracy: 0.7161\n",
      "Epoch 00001: saving model to training\\cp-0001.ckpt\n",
      "718/804 [=========================>....] - ETA: 0s - loss: 0.5753 - accuracy: 0.7151\n",
      "Epoch 00001: saving model to training\\cp-0001.ckpt\n",
      "804/804 [==============================] - 1s 957us/step - loss: 0.5735 - accuracy: 0.7158 - val_loss: 0.7545 - val_accuracy: 0.4746\n",
      "Epoch 2/50\n",
      " 79/804 [=>............................] - ETA: 0s - loss: 0.5607 - accuracy: 0.7290\n",
      "Epoch 00002: saving model to training\\cp-0002.ckpt\n",
      "312/804 [==========>...................] - ETA: 0s - loss: 0.5504 - accuracy: 0.7353\n",
      "Epoch 00002: saving model to training\\cp-0002.ckpt\n",
      "450/804 [===============>..............] - ETA: 0s - loss: 0.5531 - accuracy: 0.7328\n",
      "Epoch 00002: saving model to training\\cp-0002.ckpt\n",
      "593/804 [=====================>........] - ETA: 0s - loss: 0.5562 - accuracy: 0.7289\n",
      "Epoch 00002: saving model to training\\cp-0002.ckpt\n",
      "724/804 [==========================>...] - ETA: 0s - loss: 0.5593 - accuracy: 0.7257\n",
      "Epoch 00002: saving model to training\\cp-0002.ckpt\n",
      "804/804 [==============================] - 1s 880us/step - loss: 0.5583 - accuracy: 0.7264 - val_loss: 0.9175 - val_accuracy: 0.4746\n",
      "Epoch 3/50\n",
      "148/804 [====>.........................] - ETA: 0s - loss: 0.5607 - accuracy: 0.7219\n",
      "Epoch 00003: saving model to training\\cp-0003.ckpt\n",
      "269/804 [=========>....................] - ETA: 0s - loss: 0.5560 - accuracy: 0.7284\n",
      "Epoch 00003: saving model to training\\cp-0003.ckpt\n",
      "467/804 [================>.............] - ETA: 0s - loss: 0.5547 - accuracy: 0.7285\n",
      "Epoch 00003: saving model to training\\cp-0003.ckpt\n",
      "600/804 [=====================>........] - ETA: 0s - loss: 0.5554 - accuracy: 0.7274\n",
      "Epoch 00003: saving model to training\\cp-0003.ckpt\n",
      "731/804 [==========================>...] - ETA: 0s - loss: 0.5557 - accuracy: 0.7286\n",
      "Epoch 00003: saving model to training\\cp-0003.ckpt\n",
      "804/804 [==============================] - 1s 909us/step - loss: 0.5555 - accuracy: 0.7287 - val_loss: 0.7491 - val_accuracy: 0.4746\n",
      "Epoch 4/50\n",
      " 80/804 [=>............................] - ETA: 0s - loss: 0.5552 - accuracy: 0.7344\n",
      "Epoch 00004: saving model to training\\cp-0004.ckpt\n",
      "231/804 [=======>......................] - ETA: 0s - loss: 0.5576 - accuracy: 0.7267\n",
      "Epoch 00004: saving model to training\\cp-0004.ckpt\n",
      "386/804 [=============>................] - ETA: 0s - loss: 0.5561 - accuracy: 0.7273\n",
      "Epoch 00004: saving model to training\\cp-0004.ckpt\n",
      "557/804 [===================>..........] - ETA: 0s - loss: 0.5533 - accuracy: 0.7292\n",
      "Epoch 00004: saving model to training\\cp-0004.ckpt\n",
      "714/804 [=========================>....] - ETA: 0s - loss: 0.5541 - accuracy: 0.7290\n",
      "Epoch 00004: saving model to training\\cp-0004.ckpt\n",
      "804/804 [==============================] - 1s 829us/step - loss: 0.5539 - accuracy: 0.7288 - val_loss: 0.6933 - val_accuracy: 0.4746\n",
      "Epoch 5/50\n",
      " 77/804 [=>............................] - ETA: 0s - loss: 0.5600 - accuracy: 0.7285\n",
      "Epoch 00005: saving model to training\\cp-0005.ckpt\n",
      "223/804 [=======>......................] - ETA: 0s - loss: 0.5493 - accuracy: 0.7351\n",
      "Epoch 00005: saving model to training\\cp-0005.ckpt\n",
      "390/804 [=============>................] - ETA: 0s - loss: 0.5513 - accuracy: 0.7325\n",
      "Epoch 00005: saving model to training\\cp-0005.ckpt\n",
      "549/804 [===================>..........] - ETA: 0s - loss: 0.5507 - accuracy: 0.7308\n",
      "Epoch 00005: saving model to training\\cp-0005.ckpt\n",
      "710/804 [=========================>....] - ETA: 0s - loss: 0.5532 - accuracy: 0.7278\n",
      "Epoch 00005: saving model to training\\cp-0005.ckpt\n",
      "804/804 [==============================] - 1s 842us/step - loss: 0.5522 - accuracy: 0.7290 - val_loss: 0.6933 - val_accuracy: 0.4746\n",
      "Epoch 6/50\n",
      " 76/804 [=>............................] - ETA: 0s - loss: 0.5523 - accuracy: 0.7237\n",
      "Epoch 00006: saving model to training\\cp-0006.ckpt\n",
      "289/804 [=========>....................] - ETA: 0s - loss: 0.5514 - accuracy: 0.7285\n",
      "Epoch 00006: saving model to training\\cp-0006.ckpt\n",
      "406/804 [==============>...............] - ETA: 0s - loss: 0.5502 - accuracy: 0.7291\n",
      "Epoch 00006: saving model to training\\cp-0006.ckpt\n",
      "612/804 [=====================>........] - ETA: 0s - loss: 0.5517 - accuracy: 0.7288\n",
      "Epoch 00006: saving model to training\\cp-0006.ckpt\n",
      "743/804 [==========================>...] - ETA: 0s - loss: 0.5515 - accuracy: 0.7288\n",
      "Epoch 00006: saving model to training\\cp-0006.ckpt\n",
      "804/804 [==============================] - 1s 922us/step - loss: 0.5514 - accuracy: 0.7287 - val_loss: 0.6930 - val_accuracy: 0.5254\n",
      "Epoch 7/50\n",
      " 80/804 [=>............................] - ETA: 0s - loss: 0.5408 - accuracy: 0.7312\n",
      "Epoch 00007: saving model to training\\cp-0007.ckpt\n",
      "217/804 [=======>......................] - ETA: 0s - loss: 0.5428 - accuracy: 0.7311\n",
      "Epoch 00007: saving model to training\\cp-0007.ckpt\n",
      "444/804 [===============>..............] - ETA: 0s - loss: 0.5479 - accuracy: 0.7306\n",
      "Epoch 00007: saving model to training\\cp-0007.ckpt\n",
      "562/804 [===================>..........] - ETA: 0s - loss: 0.5499 - accuracy: 0.7283\n",
      "Epoch 00007: saving model to training\\cp-0007.ckpt\n",
      "753/804 [===========================>..] - ETA: 0s - loss: 0.5484 - accuracy: 0.7306\n",
      "Epoch 00007: saving model to training\\cp-0007.ckpt\n",
      "804/804 [==============================] - 1s 925us/step - loss: 0.5501 - accuracy: 0.7298 - val_loss: 0.7110 - val_accuracy: 0.4746\n",
      "Epoch 8/50\n",
      " 72/804 [=>............................] - ETA: 0s - loss: 0.5451 - accuracy: 0.7335\n",
      "Epoch 00008: saving model to training\\cp-0008.ckpt\n",
      "278/804 [=========>....................] - ETA: 0s - loss: 0.5475 - accuracy: 0.7333\n",
      "Epoch 00008: saving model to training\\cp-0008.ckpt\n",
      "408/804 [==============>...............] - ETA: 0s - loss: 0.5489 - accuracy: 0.7321\n",
      "Epoch 00008: saving model to training\\cp-0008.ckpt\n",
      "594/804 [=====================>........] - ETA: 0s - loss: 0.5491 - accuracy: 0.7317\n",
      "Epoch 00008: saving model to training\\cp-0008.ckpt\n",
      "734/804 [==========================>...] - ETA: 0s - loss: 0.5492 - accuracy: 0.7291\n",
      "Epoch 00008: saving model to training\\cp-0008.ckpt\n",
      "804/804 [==============================] - 1s 924us/step - loss: 0.5491 - accuracy: 0.7293 - val_loss: 0.7937 - val_accuracy: 0.4746\n",
      "Epoch 9/50\n",
      " 82/804 [==>...........................] - ETA: 0s - loss: 0.5405 - accuracy: 0.7401\n",
      "Epoch 00009: saving model to training\\cp-0009.ckpt\n",
      "226/804 [=======>......................] - ETA: 0s - loss: 0.5387 - accuracy: 0.7387\n",
      "Epoch 00009: saving model to training\\cp-0009.ckpt\n",
      "366/804 [============>.................] - ETA: 0s - loss: 0.5429 - accuracy: 0.7351\n",
      "Epoch 00009: saving model to training\\cp-0009.ckpt\n",
      "534/804 [==================>...........] - ETA: 0s - loss: 0.5462 - accuracy: 0.7329\n",
      "Epoch 00009: saving model to training\\cp-0009.ckpt\n",
      "692/804 [========================>.....] - ETA: 0s - loss: 0.5465 - accuracy: 0.7316\n",
      "Epoch 00009: saving model to training\\cp-0009.ckpt\n",
      "804/804 [==============================] - 1s 845us/step - loss: 0.5486 - accuracy: 0.7301 - val_loss: 0.7192 - val_accuracy: 0.4746\n",
      "Epoch 10/50\n",
      " 75/804 [=>............................] - ETA: 0s - loss: 0.5259 - accuracy: 0.7412\n",
      "Epoch 00010: saving model to training\\cp-0010.ckpt\n",
      "272/804 [=========>....................] - ETA: 0s - loss: 0.5439 - accuracy: 0.7344\n",
      "Epoch 00010: saving model to training\\cp-0010.ckpt\n",
      "409/804 [==============>...............] - ETA: 0s - loss: 0.5418 - accuracy: 0.7379\n",
      "Epoch 00010: saving model to training\\cp-0010.ckpt\n",
      "527/804 [==================>...........] - ETA: 0s - loss: 0.5449 - accuracy: 0.7358\n",
      "Epoch 00010: saving model to training\\cp-0010.ckpt\n",
      "679/804 [========================>.....] - ETA: 0s - loss: 0.5463 - accuracy: 0.7337\n",
      "Epoch 00010: saving model to training\\cp-0010.ckpt\n",
      "804/804 [==============================] - 1s 899us/step - loss: 0.5485 - accuracy: 0.7310 - val_loss: 0.7106 - val_accuracy: 0.4746\n",
      "Epoch 11/50\n",
      " 81/804 [==>...........................] - ETA: 0s - loss: 0.5635 - accuracy: 0.7188\n",
      "Epoch 00011: saving model to training\\cp-0011.ckpt\n",
      "216/804 [=======>......................] - ETA: 0s - loss: 0.5511 - accuracy: 0.7299\n",
      "Epoch 00011: saving model to training\\cp-0011.ckpt\n",
      "419/804 [==============>...............] - ETA: 0s - loss: 0.5476 - accuracy: 0.7281\n",
      "Epoch 00011: saving model to training\\cp-0011.ckpt\n",
      "539/804 [===================>..........] - ETA: 0s - loss: 0.5463 - accuracy: 0.7299\n",
      "Epoch 00011: saving model to training\\cp-0011.ckpt\n",
      "731/804 [==========================>...] - ETA: 0s - loss: 0.5486 - accuracy: 0.7298\n",
      "Epoch 00011: saving model to training\\cp-0011.ckpt\n",
      "804/804 [==============================] - 1s 952us/step - loss: 0.5479 - accuracy: 0.7307 - val_loss: 0.7559 - val_accuracy: 0.4746\n",
      "Epoch 12/50\n",
      " 68/804 [=>............................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7316\n",
      "Epoch 00012: saving model to training\\cp-0012.ckpt\n",
      "268/804 [=========>....................] - ETA: 0s - loss: 0.5402 - accuracy: 0.7341\n",
      "Epoch 00012: saving model to training\\cp-0012.ckpt\n",
      "392/804 [=============>................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7333\n",
      "Epoch 00012: saving model to training\\cp-0012.ckpt\n",
      "591/804 [=====================>........] - ETA: 0s - loss: 0.5439 - accuracy: 0.7324\n",
      "Epoch 00012: saving model to training\\cp-0012.ckpt\n",
      "737/804 [==========================>...] - ETA: 0s - loss: 0.5464 - accuracy: 0.7310\n",
      "Epoch 00012: saving model to training\\cp-0012.ckpt\n",
      "804/804 [==============================] - 1s 907us/step - loss: 0.5472 - accuracy: 0.7302 - val_loss: 0.7167 - val_accuracy: 0.4746\n",
      "Epoch 13/50\n",
      " 73/804 [=>............................] - ETA: 0s - loss: 0.5416 - accuracy: 0.7397\n",
      "Epoch 00013: saving model to training\\cp-0013.ckpt\n",
      "202/804 [======>.......................] - ETA: 0s - loss: 0.5478 - accuracy: 0.7287\n",
      "Epoch 00013: saving model to training\\cp-0013.ckpt\n",
      "414/804 [==============>...............] - ETA: 0s - loss: 0.5481 - accuracy: 0.7272\n",
      "Epoch 00013: saving model to training\\cp-0013.ckpt\n",
      "534/804 [==================>...........] - ETA: 0s - loss: 0.5461 - accuracy: 0.7310\n",
      "Epoch 00013: saving model to training\\cp-0013.ckpt\n",
      "731/804 [==========================>...] - ETA: 0s - loss: 0.5466 - accuracy: 0.7310\n",
      "Epoch 00013: saving model to training\\cp-0013.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5472 - accuracy: 0.7311 - val_loss: 0.7267 - val_accuracy: 0.4746\n",
      "Epoch 14/50\n",
      " 74/804 [=>............................] - ETA: 0s - loss: 0.5481 - accuracy: 0.7335\n",
      "Epoch 00014: saving model to training\\cp-0014.ckpt\n",
      "258/804 [========>.....................] - ETA: 0s - loss: 0.5488 - accuracy: 0.7292\n",
      "Epoch 00014: saving model to training\\cp-0014.ckpt\n",
      "374/804 [============>.................] - ETA: 0s - loss: 0.5457 - accuracy: 0.7325\n",
      "Epoch 00014: saving model to training\\cp-0014.ckpt\n",
      "573/804 [====================>.........] - ETA: 0s - loss: 0.5465 - accuracy: 0.7310\n",
      "Epoch 00014: saving model to training\\cp-0014.ckpt\n",
      "698/804 [=========================>....] - ETA: 0s - loss: 0.5470 - accuracy: 0.7303\n",
      "Epoch 00014: saving model to training\\cp-0014.ckpt\n",
      "804/804 [==============================] - 1s 956us/step - loss: 0.5465 - accuracy: 0.7312 - val_loss: 0.6963 - val_accuracy: 0.4746\n",
      "Epoch 15/50\n",
      " 72/804 [=>............................] - ETA: 0s - loss: 0.5498 - accuracy: 0.7300\n",
      "Epoch 00015: saving model to training\\cp-0015.ckpt\n",
      "205/804 [======>.......................] - ETA: 0s - loss: 0.5416 - accuracy: 0.7366\n",
      "Epoch 00015: saving model to training\\cp-0015.ckpt\n",
      "419/804 [==============>...............] - ETA: 0s - loss: 0.5439 - accuracy: 0.7358\n",
      "Epoch 00015: saving model to training\\cp-0015.ckpt\n",
      "555/804 [===================>..........] - ETA: 0s - loss: 0.5446 - accuracy: 0.7337\n",
      "Epoch 00015: saving model to training\\cp-0015.ckpt\n",
      "682/804 [========================>.....] - ETA: 0s - loss: 0.5435 - accuracy: 0.7352\n",
      "Epoch 00015: saving model to training\\cp-0015.ckpt\n",
      "804/804 [==============================] - 1s 895us/step - loss: 0.5462 - accuracy: 0.7329 - val_loss: 0.6940 - val_accuracy: 0.4746\n",
      "Epoch 16/50\n",
      " 75/804 [=>............................] - ETA: 0s - loss: 0.5450 - accuracy: 0.7254\n",
      "Epoch 00016: saving model to training\\cp-0016.ckpt\n",
      "214/804 [======>.......................] - ETA: 0s - loss: 0.5494 - accuracy: 0.7252\n",
      "Epoch 00016: saving model to training\\cp-0016.ckpt\n",
      "411/804 [==============>...............] - ETA: 0s - loss: 0.5483 - accuracy: 0.7259\n",
      "Epoch 00016: saving model to training\\cp-0016.ckpt\n",
      "541/804 [===================>..........] - ETA: 0s - loss: 0.5472 - accuracy: 0.7280\n",
      "Epoch 00016: saving model to training\\cp-0016.ckpt\n",
      "669/804 [=======================>......] - ETA: 0s - loss: 0.5480 - accuracy: 0.7280\n",
      "Epoch 00016: saving model to training\\cp-0016.ckpt\n",
      "804/804 [==============================] - 1s 902us/step - loss: 0.5455 - accuracy: 0.7309 - val_loss: 0.7620 - val_accuracy: 0.4746\n",
      "Epoch 17/50\n",
      " 73/804 [=>............................] - ETA: 0s - loss: 0.5503 - accuracy: 0.7307\n",
      "Epoch 00017: saving model to training\\cp-0017.ckpt\n",
      "192/804 [======>.......................] - ETA: 0s - loss: 0.5499 - accuracy: 0.7306\n",
      "Epoch 00017: saving model to training\\cp-0017.ckpt\n",
      "412/804 [==============>...............] - ETA: 0s - loss: 0.5453 - accuracy: 0.7351\n",
      "Epoch 00017: saving model to training\\cp-0017.ckpt\n",
      "558/804 [===================>..........] - ETA: 0s - loss: 0.5455 - accuracy: 0.7336\n",
      "Epoch 00017: saving model to training\\cp-0017.ckpt\n",
      "696/804 [========================>.....] - ETA: 0s - loss: 0.5462 - accuracy: 0.7322\n",
      "Epoch 00017: saving model to training\\cp-0017.ckpt\n",
      "804/804 [==============================] - 1s 941us/step - loss: 0.5454 - accuracy: 0.7327 - val_loss: 0.7318 - val_accuracy: 0.4746\n",
      "Epoch 18/50\n",
      " 79/804 [=>............................] - ETA: 0s - loss: 0.5438 - accuracy: 0.7373\n",
      "Epoch 00018: saving model to training\\cp-0018.ckpt\n",
      "221/804 [=======>......................] - ETA: 0s - loss: 0.5400 - accuracy: 0.7360\n",
      "Epoch 00018: saving model to training\\cp-0018.ckpt\n",
      "365/804 [============>.................] - ETA: 0s - loss: 0.5407 - accuracy: 0.7356\n",
      "Epoch 00018: saving model to training\\cp-0018.ckpt\n",
      "497/804 [=================>............] - ETA: 0s - loss: 0.5427 - accuracy: 0.7355\n",
      "Epoch 00018: saving model to training\\cp-0018.ckpt\n",
      "652/804 [=======================>......] - ETA: 0s - loss: 0.5436 - accuracy: 0.7355\n",
      "Epoch 00018: saving model to training\\cp-0018.ckpt\n",
      "804/804 [==============================] - 1s 872us/step - loss: 0.5454 - accuracy: 0.7336 - val_loss: 0.7282 - val_accuracy: 0.4746\n",
      "Epoch 19/50\n",
      " 81/804 [==>...........................] - ETA: 0s - loss: 0.5467 - accuracy: 0.7288\n",
      "Epoch 00019: saving model to training\\cp-0019.ckpt\n",
      "212/804 [======>.......................] - ETA: 0s - loss: 0.5386 - accuracy: 0.7357\n",
      "Epoch 00019: saving model to training\\cp-0019.ckpt\n",
      "340/804 [===========>..................] - ETA: 0s - loss: 0.5401 - accuracy: 0.7377\n",
      "Epoch 00019: saving model to training\\cp-0019.ckpt\n",
      "483/804 [=================>............] - ETA: 0s - loss: 0.5420 - accuracy: 0.7352\n",
      "Epoch 00019: saving model to training\\cp-0019.ckpt\n",
      "646/804 [=======================>......] - ETA: 0s - loss: 0.5427 - accuracy: 0.7342\n",
      "Epoch 00019: saving model to training\\cp-0019.ckpt\n",
      "804/804 [==============================] - 1s 876us/step - loss: 0.5443 - accuracy: 0.7332 - val_loss: 0.7103 - val_accuracy: 0.4746\n",
      "Epoch 20/50\n",
      " 65/804 [=>............................] - ETA: 0s - loss: 0.5326 - accuracy: 0.7370\n",
      "Epoch 00020: saving model to training\\cp-0020.ckpt\n",
      "200/804 [======>.......................] - ETA: 0s - loss: 0.5509 - accuracy: 0.7266\n",
      "Epoch 00020: saving model to training\\cp-0020.ckpt\n",
      "333/804 [===========>..................] - ETA: 0s - loss: 0.5475 - accuracy: 0.7309\n",
      "Epoch 00020: saving model to training\\cp-0020.ckpt\n",
      "562/804 [===================>..........] - ETA: 0s - loss: 0.5456 - accuracy: 0.7309\n",
      "Epoch 00020: saving model to training\\cp-0020.ckpt\n",
      "708/804 [=========================>....] - ETA: 0s - loss: 0.5445 - accuracy: 0.7316\n",
      "Epoch 00020: saving model to training\\cp-0020.ckpt\n",
      "804/804 [==============================] - 1s 881us/step - loss: 0.5440 - accuracy: 0.7332 - val_loss: 0.6920 - val_accuracy: 0.5254\n",
      "Epoch 21/50\n",
      " 77/804 [=>............................] - ETA: 0s - loss: 0.5403 - accuracy: 0.7378\n",
      "Epoch 00021: saving model to training\\cp-0021.ckpt\n",
      "215/804 [=======>......................] - ETA: 0s - loss: 0.5431 - accuracy: 0.7311\n",
      "Epoch 00021: saving model to training\\cp-0021.ckpt\n",
      "349/804 [============>.................] - ETA: 0s - loss: 0.5374 - accuracy: 0.7376\n",
      "Epoch 00021: saving model to training\\cp-0021.ckpt\n",
      "481/804 [================>.............] - ETA: 0s - loss: 0.5412 - accuracy: 0.7341\n",
      "Epoch 00021: saving model to training\\cp-0021.ckpt\n",
      "716/804 [=========================>....] - ETA: 0s - loss: 0.5436 - accuracy: 0.7327\n",
      "Epoch 00021: saving model to training\\cp-0021.ckpt\n",
      "804/804 [==============================] - 1s 892us/step - loss: 0.5439 - accuracy: 0.7323 - val_loss: 0.6929 - val_accuracy: 0.5254\n",
      "Epoch 22/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.4809 - accuracy: 0.8125\n",
      "Epoch 00022: saving model to training\\cp-0022.ckpt\n",
      "234/804 [=======>......................] - ETA: 0s - loss: 0.5409 - accuracy: 0.7364\n",
      "Epoch 00022: saving model to training\\cp-0022.ckpt\n",
      "348/804 [===========>..................] - ETA: 0s - loss: 0.5421 - accuracy: 0.7350\n",
      "Epoch 00022: saving model to training\\cp-0022.ckpt\n",
      "535/804 [==================>...........] - ETA: 0s - loss: 0.5425 - accuracy: 0.7346\n",
      "Epoch 00022: saving model to training\\cp-0022.ckpt\n",
      "700/804 [=========================>....] - ETA: 0s - loss: 0.5430 - accuracy: 0.7351\n",
      "Epoch 00022: saving model to training\\cp-0022.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5439 - accuracy: 0.7346 - val_loss: 0.7475 - val_accuracy: 0.4746\n",
      "Epoch 23/50\n",
      " 50/804 [>.............................] - ETA: 0s - loss: 0.5428 - accuracy: 0.7387\n",
      "Epoch 00023: saving model to training\\cp-0023.ckpt\n",
      "215/804 [=======>......................] - ETA: 0s - loss: 0.5423 - accuracy: 0.7365\n",
      "Epoch 00023: saving model to training\\cp-0023.ckpt\n",
      "359/804 [============>.................] - ETA: 0s - loss: 0.5475 - accuracy: 0.7299\n",
      "Epoch 00023: saving model to training\\cp-0023.ckpt\n",
      "547/804 [===================>..........] - ETA: 0s - loss: 0.5421 - accuracy: 0.7338\n",
      "Epoch 00023: saving model to training\\cp-0023.ckpt\n",
      "685/804 [========================>.....] - ETA: 0s - loss: 0.5423 - accuracy: 0.7341\n",
      "Epoch 00023: saving model to training\\cp-0023.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7335 - val_loss: 0.7091 - val_accuracy: 0.4746\n",
      "Epoch 24/50\n",
      " 53/804 [>.............................] - ETA: 0s - loss: 0.5423 - accuracy: 0.7300\n",
      "Epoch 00024: saving model to training\\cp-0024.ckpt\n",
      "202/804 [======>.......................] - ETA: 0s - loss: 0.5379 - accuracy: 0.7321\n",
      "Epoch 00024: saving model to training\\cp-0024.ckpt\n",
      "343/804 [===========>..................] - ETA: 0s - loss: 0.5437 - accuracy: 0.7298\n",
      "Epoch 00024: saving model to training\\cp-0024.ckpt\n",
      "497/804 [=================>............] - ETA: 0s - loss: 0.5445 - accuracy: 0.7320\n",
      "Epoch 00024: saving model to training\\cp-0024.ckpt\n",
      "701/804 [=========================>....] - ETA: 0s - loss: 0.5421 - accuracy: 0.7340\n",
      "Epoch 00024: saving model to training\\cp-0024.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5433 - accuracy: 0.7331 - val_loss: 0.7059 - val_accuracy: 0.4746\n",
      "Epoch 25/50\n",
      " 52/804 [>.............................] - ETA: 0s - loss: 0.5561 - accuracy: 0.7242\n",
      "Epoch 00025: saving model to training\\cp-0025.ckpt\n",
      "203/804 [======>.......................] - ETA: 0s - loss: 0.5387 - accuracy: 0.7389\n",
      "Epoch 00025: saving model to training\\cp-0025.ckpt\n",
      "342/804 [===========>..................] - ETA: 0s - loss: 0.5452 - accuracy: 0.7338\n",
      "Epoch 00025: saving model to training\\cp-0025.ckpt\n",
      "492/804 [=================>............] - ETA: 0s - loss: 0.5438 - accuracy: 0.7335\n",
      "Epoch 00025: saving model to training\\cp-0025.ckpt\n",
      "699/804 [=========================>....] - ETA: 0s - loss: 0.5430 - accuracy: 0.7348\n",
      "Epoch 00025: saving model to training\\cp-0025.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7347 - val_loss: 0.6960 - val_accuracy: 0.4746\n",
      "Epoch 26/50\n",
      " 51/804 [>.............................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7384\n",
      "Epoch 00026: saving model to training\\cp-0026.ckpt\n",
      "189/804 [======>.......................] - ETA: 0s - loss: 0.5456 - accuracy: 0.7305\n",
      "Epoch 00026: saving model to training\\cp-0026.ckpt\n",
      "331/804 [===========>..................] - ETA: 0s - loss: 0.5448 - accuracy: 0.7329\n",
      "Epoch 00026: saving model to training\\cp-0026.ckpt\n",
      "536/804 [===================>..........] - ETA: 0s - loss: 0.5445 - accuracy: 0.7324\n",
      "Epoch 00026: saving model to training\\cp-0026.ckpt\n",
      "663/804 [=======================>......] - ETA: 0s - loss: 0.5428 - accuracy: 0.7333\n",
      "Epoch 00026: saving model to training\\cp-0026.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7351 - val_loss: 0.6959 - val_accuracy: 0.5254\n",
      "Epoch 27/50\n",
      " 54/804 [=>............................] - ETA: 0s - loss: 0.5447 - accuracy: 0.7338\n",
      "Epoch 00027: saving model to training\\cp-0027.ckpt\n",
      "159/804 [====>.........................] - ETA: 0s - loss: 0.5422 - accuracy: 0.7366\n",
      "Epoch 00027: saving model to training\\cp-0027.ckpt\n",
      "331/804 [===========>..................] - ETA: 0s - loss: 0.5481 - accuracy: 0.7314\n",
      "Epoch 00027: saving model to training\\cp-0027.ckpt\n",
      "482/804 [================>.............] - ETA: 0s - loss: 0.5447 - accuracy: 0.7343\n",
      "Epoch 00027: saving model to training\\cp-0027.ckpt\n",
      "643/804 [======================>.......] - ETA: 0s - loss: 0.5435 - accuracy: 0.7336\n",
      "Epoch 00027: saving model to training\\cp-0027.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7344 - val_loss: 0.6930 - val_accuracy: 0.5254\n",
      "Epoch 28/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.4630 - accuracy: 0.8125\n",
      "Epoch 00028: saving model to training\\cp-0028.ckpt\n",
      "176/804 [=====>........................] - ETA: 0s - loss: 0.5365 - accuracy: 0.7377\n",
      "Epoch 00028: saving model to training\\cp-0028.ckpt\n",
      "324/804 [===========>..................] - ETA: 0s - loss: 0.5405 - accuracy: 0.7343\n",
      "Epoch 00028: saving model to training\\cp-0028.ckpt\n",
      "531/804 [==================>...........] - ETA: 0s - loss: 0.5399 - accuracy: 0.7356\n",
      "Epoch 00028: saving model to training\\cp-0028.ckpt\n",
      "660/804 [=======================>......] - ETA: 0s - loss: 0.5420 - accuracy: 0.7341\n",
      "Epoch 00028: saving model to training\\cp-0028.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7338 - val_loss: 0.6954 - val_accuracy: 0.4746\n",
      "Epoch 29/50\n",
      "  1/804 [..............................] - ETA: 2s - loss: 0.4065 - accuracy: 0.8750\n",
      "Epoch 00029: saving model to training\\cp-0029.ckpt\n",
      "175/804 [=====>........................] - ETA: 0s - loss: 0.5379 - accuracy: 0.7409\n",
      "Epoch 00029: saving model to training\\cp-0029.ckpt\n",
      "323/804 [===========>..................] - ETA: 0s - loss: 0.5419 - accuracy: 0.7346\n",
      "Epoch 00029: saving model to training\\cp-0029.ckpt\n",
      "476/804 [================>.............] - ETA: 0s - loss: 0.5462 - accuracy: 0.7326\n",
      "Epoch 00029: saving model to training\\cp-0029.ckpt\n",
      "641/804 [======================>.......] - ETA: 0s - loss: 0.5427 - accuracy: 0.7343\n",
      "Epoch 00029: saving model to training\\cp-0029.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5425 - accuracy: 0.7343 - val_loss: 0.7022 - val_accuracy: 0.5254\n",
      "Epoch 30/50\n",
      "  1/804 [..............................] - ETA: 2s - loss: 0.6269 - accuracy: 0.6250\n",
      "Epoch 00030: saving model to training\\cp-0030.ckpt\n",
      "165/804 [=====>........................] - ETA: 0s - loss: 0.5436 - accuracy: 0.7369\n",
      "Epoch 00030: saving model to training\\cp-0030.ckpt\n",
      "321/804 [==========>...................] - ETA: 0s - loss: 0.5455 - accuracy: 0.7370\n",
      "Epoch 00030: saving model to training\\cp-0030.ckpt\n",
      "471/804 [================>.............] - ETA: 0s - loss: 0.5460 - accuracy: 0.7335\n",
      "Epoch 00030: saving model to training\\cp-0030.ckpt\n",
      "636/804 [======================>.......] - ETA: 0s - loss: 0.5448 - accuracy: 0.7335\n",
      "Epoch 00030: saving model to training\\cp-0030.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7362 - val_loss: 0.7060 - val_accuracy: 0.5254\n",
      "Epoch 31/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.4850 - accuracy: 0.7812\n",
      "Epoch 00031: saving model to training\\cp-0031.ckpt\n",
      "168/804 [=====>........................] - ETA: 0s - loss: 0.5389 - accuracy: 0.7396\n",
      "Epoch 00031: saving model to training\\cp-0031.ckpt\n",
      "316/804 [==========>...................] - ETA: 0s - loss: 0.5406 - accuracy: 0.7366\n",
      "Epoch 00031: saving model to training\\cp-0031.ckpt\n",
      "465/804 [================>.............] - ETA: 0s - loss: 0.5396 - accuracy: 0.7358\n",
      "Epoch 00031: saving model to training\\cp-0031.ckpt\n",
      "625/804 [======================>.......] - ETA: 0s - loss: 0.5414 - accuracy: 0.7355\n",
      "Epoch 00031: saving model to training\\cp-0031.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7345 - val_loss: 0.7202 - val_accuracy: 0.4746\n",
      "Epoch 32/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.6313 - accuracy: 0.6562\n",
      "Epoch 00032: saving model to training\\cp-0032.ckpt\n",
      "158/804 [====>.........................] - ETA: 0s - loss: 0.5362 - accuracy: 0.7322\n",
      "Epoch 00032: saving model to training\\cp-0032.ckpt\n",
      "303/804 [==========>...................] - ETA: 0s - loss: 0.5461 - accuracy: 0.7277\n",
      "Epoch 00032: saving model to training\\cp-0032.ckpt\n",
      "460/804 [================>.............] - ETA: 0s - loss: 0.5446 - accuracy: 0.7317\n",
      "Epoch 00032: saving model to training\\cp-0032.ckpt\n",
      "662/804 [=======================>......] - ETA: 0s - loss: 0.5432 - accuracy: 0.7337\n",
      "Epoch 00032: saving model to training\\cp-0032.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7353 - val_loss: 0.6920 - val_accuracy: 0.5254\n",
      "Epoch 33/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.5273 - accuracy: 0.7188\n",
      "Epoch 00033: saving model to training\\cp-0033.ckpt\n",
      "156/804 [====>.........................] - ETA: 0s - loss: 0.5366 - accuracy: 0.7294\n",
      "Epoch 00033: saving model to training\\cp-0033.ckpt\n",
      "307/804 [==========>...................] - ETA: 0s - loss: 0.5354 - accuracy: 0.7335\n",
      "Epoch 00033: saving model to training\\cp-0033.ckpt\n",
      "461/804 [================>.............] - ETA: 0s - loss: 0.5377 - accuracy: 0.7354\n",
      "Epoch 00033: saving model to training\\cp-0033.ckpt\n",
      "617/804 [======================>.......] - ETA: 0s - loss: 0.5377 - accuracy: 0.7367\n",
      "Epoch 00033: saving model to training\\cp-0033.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5412 - accuracy: 0.7344 - val_loss: 0.6925 - val_accuracy: 0.5254\n",
      "Epoch 34/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.7810 - accuracy: 0.5312\n",
      "Epoch 00034: saving model to training\\cp-0034.ckpt\n",
      "173/804 [=====>........................] - ETA: 0s - loss: 0.5458 - accuracy: 0.7276\n",
      "Epoch 00034: saving model to training\\cp-0034.ckpt\n",
      "329/804 [===========>..................] - ETA: 0s - loss: 0.5511 - accuracy: 0.7269\n",
      "Epoch 00034: saving model to training\\cp-0034.ckpt\n",
      "458/804 [================>.............] - ETA: 0s - loss: 0.5464 - accuracy: 0.7313\n",
      "Epoch 00034: saving model to training\\cp-0034.ckpt\n",
      "612/804 [=====================>........] - ETA: 0s - loss: 0.5434 - accuracy: 0.7328\n",
      "Epoch 00034: saving model to training\\cp-0034.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7343 - val_loss: 0.6922 - val_accuracy: 0.5254\n",
      "Epoch 35/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.5143 - accuracy: 0.7500\n",
      "Epoch 00035: saving model to training\\cp-0035.ckpt\n",
      "140/804 [====>.........................] - ETA: 0s - loss: 0.5455 - accuracy: 0.7362\n",
      "Epoch 00035: saving model to training\\cp-0035.ckpt\n",
      "291/804 [=========>....................] - ETA: 0s - loss: 0.5455 - accuracy: 0.7326\n",
      "Epoch 00035: saving model to training\\cp-0035.ckpt\n",
      "449/804 [===============>..............] - ETA: 0s - loss: 0.5446 - accuracy: 0.7325\n",
      "Epoch 00035: saving model to training\\cp-0035.ckpt\n",
      "612/804 [=====================>........] - ETA: 0s - loss: 0.5418 - accuracy: 0.7350\n",
      "Epoch 00035: saving model to training\\cp-0035.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7362 - val_loss: 0.7061 - val_accuracy: 0.5254\n",
      "Epoch 36/50\n",
      "  1/804 [..............................] - ETA: 2s - loss: 0.5421 - accuracy: 0.7500\n",
      "Epoch 00036: saving model to training\\cp-0036.ckpt\n",
      "147/804 [====>.........................] - ETA: 0s - loss: 0.5378 - accuracy: 0.7317\n",
      "Epoch 00036: saving model to training\\cp-0036.ckpt\n",
      "302/804 [==========>...................] - ETA: 0s - loss: 0.5363 - accuracy: 0.7382\n",
      "Epoch 00036: saving model to training\\cp-0036.ckpt\n",
      "454/804 [===============>..............] - ETA: 0s - loss: 0.5416 - accuracy: 0.7344\n",
      "Epoch 00036: saving model to training\\cp-0036.ckpt\n",
      "609/804 [=====================>........] - ETA: 0s - loss: 0.5402 - accuracy: 0.7360\n",
      "Epoch 00036: saving model to training\\cp-0036.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7358 - val_loss: 0.7230 - val_accuracy: 0.4746\n",
      "Epoch 37/50\n",
      "  1/804 [..............................] - ETA: 2s - loss: 0.5134 - accuracy: 0.7812\n",
      "Epoch 00037: saving model to training\\cp-0037.ckpt\n",
      "143/804 [====>.........................] - ETA: 0s - loss: 0.5402 - accuracy: 0.7386\n",
      "Epoch 00037: saving model to training\\cp-0037.ckpt\n",
      "293/804 [=========>....................] - ETA: 0s - loss: 0.5412 - accuracy: 0.7365\n",
      "Epoch 00037: saving model to training\\cp-0037.ckpt\n",
      "462/804 [================>.............] - ETA: 0s - loss: 0.5429 - accuracy: 0.7352\n",
      "Epoch 00037: saving model to training\\cp-0037.ckpt\n",
      "652/804 [=======================>......] - ETA: 0s - loss: 0.5386 - accuracy: 0.7388\n",
      "Epoch 00037: saving model to training\\cp-0037.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7362 - val_loss: 0.7011 - val_accuracy: 0.4746\n",
      "Epoch 38/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.6613 - accuracy: 0.5312\n",
      "Epoch 00038: saving model to training\\cp-0038.ckpt\n",
      "150/804 [====>.........................] - ETA: 0s - loss: 0.5356 - accuracy: 0.7369\n",
      "Epoch 00038: saving model to training\\cp-0038.ckpt\n",
      "303/804 [==========>...................] - ETA: 0s - loss: 0.5383 - accuracy: 0.7386\n",
      "Epoch 00038: saving model to training\\cp-0038.ckpt\n",
      "445/804 [===============>..............] - ETA: 0s - loss: 0.5400 - accuracy: 0.7360\n",
      "Epoch 00038: saving model to training\\cp-0038.ckpt\n",
      "651/804 [=======================>......] - ETA: 0s - loss: 0.5396 - accuracy: 0.7372\n",
      "Epoch 00038: saving model to training\\cp-0038.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7363 - val_loss: 0.7160 - val_accuracy: 0.4746\n",
      "Epoch 39/50\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.4936 - accuracy: 0.7812\n",
      "Epoch 00039: saving model to training\\cp-0039.ckpt\n",
      "154/804 [====>.........................] - ETA: 0s - loss: 0.5280 - accuracy: 0.7463\n",
      "Epoch 00039: saving model to training\\cp-0039.ckpt\n",
      "312/804 [==========>...................] - ETA: 0s - loss: 0.5356 - accuracy: 0.7384\n",
      "Epoch 00039: saving model to training\\cp-0039.ckpt\n",
      "465/804 [================>.............] - ETA: 0s - loss: 0.5373 - accuracy: 0.7366\n",
      "Epoch 00039: saving model to training\\cp-0039.ckpt\n",
      "599/804 [=====================>........] - ETA: 0s - loss: 0.5389 - accuracy: 0.7374\n",
      "Epoch 00039: saving model to training\\cp-0039.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7363 - val_loss: 0.6981 - val_accuracy: 0.4746\n",
      "Epoch 40/50\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.5887 - accuracy: 0.7188\n",
      "Epoch 00040: saving model to training\\cp-0040.ckpt\n",
      "156/804 [====>.........................] - ETA: 0s - loss: 0.5400 - accuracy: 0.7316\n",
      "Epoch 00040: saving model to training\\cp-0040.ckpt\n",
      "261/804 [========>.....................] - ETA: 0s - loss: 0.5350 - accuracy: 0.7373\n",
      "Epoch 00040: saving model to training\\cp-0040.ckpt\n",
      "433/804 [===============>..............] - ETA: 0s - loss: 0.5380 - accuracy: 0.7356\n",
      "Epoch 00040: saving model to training\\cp-0040.ckpt\n",
      "591/804 [=====================>........] - ETA: 0s - loss: 0.5389 - accuracy: 0.7361\n",
      "Epoch 00040: saving model to training\\cp-0040.ckpt\n",
      "802/804 [============================>.] - ETA: 0s - loss: 0.5401 - accuracy: 0.7362\n",
      "Epoch 00040: saving model to training\\cp-0040.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7362 - val_loss: 0.6998 - val_accuracy: 0.4746\n",
      "Epoch 41/50\n",
      "121/804 [===>..........................] - ETA: 0s - loss: 0.5440 - accuracy: 0.7296\n",
      "Epoch 00041: saving model to training\\cp-0041.ckpt\n",
      "283/804 [=========>....................] - ETA: 0s - loss: 0.5395 - accuracy: 0.7356\n",
      "Epoch 00041: saving model to training\\cp-0041.ckpt\n",
      "426/804 [==============>...............] - ETA: 0s - loss: 0.5416 - accuracy: 0.7343\n",
      "Epoch 00041: saving model to training\\cp-0041.ckpt\n",
      "604/804 [=====================>........] - ETA: 0s - loss: 0.5403 - accuracy: 0.7353\n",
      "Epoch 00041: saving model to training\\cp-0041.ckpt\n",
      "796/804 [============================>.] - ETA: 0s - loss: 0.5404 - accuracy: 0.7353\n",
      "Epoch 00041: saving model to training\\cp-0041.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.7356 - val_loss: 0.6941 - val_accuracy: 0.4746\n",
      "Epoch 42/50\n",
      "112/804 [===>..........................] - ETA: 0s - loss: 0.5265 - accuracy: 0.7458\n",
      "Epoch 00042: saving model to training\\cp-0042.ckpt\n",
      "273/804 [=========>....................] - ETA: 0s - loss: 0.5424 - accuracy: 0.7364\n",
      "Epoch 00042: saving model to training\\cp-0042.ckpt\n",
      "472/804 [================>.............] - ETA: 0s - loss: 0.5428 - accuracy: 0.7368\n",
      "Epoch 00042: saving model to training\\cp-0042.ckpt\n",
      "611/804 [=====================>........] - ETA: 0s - loss: 0.5412 - accuracy: 0.7374\n",
      "Epoch 00042: saving model to training\\cp-0042.ckpt\n",
      "746/804 [==========================>...] - ETA: 0s - loss: 0.5395 - accuracy: 0.7382\n",
      "Epoch 00042: saving model to training\\cp-0042.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7371 - val_loss: 0.6922 - val_accuracy: 0.5254\n",
      "Epoch 43/50\n",
      "117/804 [===>..........................] - ETA: 0s - loss: 0.5421 - accuracy: 0.7337\n",
      "Epoch 00043: saving model to training\\cp-0043.ckpt\n",
      "274/804 [=========>....................] - ETA: 0s - loss: 0.5427 - accuracy: 0.7333\n",
      "Epoch 00043: saving model to training\\cp-0043.ckpt\n",
      "468/804 [================>.............] - ETA: 0s - loss: 0.5410 - accuracy: 0.7353\n",
      "Epoch 00043: saving model to training\\cp-0043.ckpt\n",
      "590/804 [=====================>........] - ETA: 0s - loss: 0.5391 - accuracy: 0.7369\n",
      "Epoch 00043: saving model to training\\cp-0043.ckpt\n",
      "779/804 [============================>.] - ETA: 0s - loss: 0.5394 - accuracy: 0.7370\n",
      "Epoch 00043: saving model to training\\cp-0043.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7369 - val_loss: 0.6942 - val_accuracy: 0.4746\n",
      "Epoch 44/50\n",
      "116/804 [===>..........................] - ETA: 0s - loss: 0.5302 - accuracy: 0.7454\n",
      "Epoch 00044: saving model to training\\cp-0044.ckpt\n",
      "265/804 [========>.....................] - ETA: 0s - loss: 0.5415 - accuracy: 0.7370\n",
      "Epoch 00044: saving model to training\\cp-0044.ckpt\n",
      "466/804 [================>.............] - ETA: 0s - loss: 0.5412 - accuracy: 0.7375\n",
      "Epoch 00044: saving model to training\\cp-0044.ckpt\n",
      "594/804 [=====================>........] - ETA: 0s - loss: 0.5413 - accuracy: 0.7375\n",
      "Epoch 00044: saving model to training\\cp-0044.ckpt\n",
      "783/804 [============================>.] - ETA: 0s - loss: 0.5394 - accuracy: 0.7384\n",
      "Epoch 00044: saving model to training\\cp-0044.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.7382 - val_loss: 0.6940 - val_accuracy: 0.4746\n",
      "Epoch 45/50\n",
      "111/804 [===>..........................] - ETA: 0s - loss: 0.5559 - accuracy: 0.7176\n",
      "Epoch 00045: saving model to training\\cp-0045.ckpt\n",
      "278/804 [=========>....................] - ETA: 0s - loss: 0.5433 - accuracy: 0.7346\n",
      "Epoch 00045: saving model to training\\cp-0045.ckpt\n",
      "410/804 [==============>...............] - ETA: 0s - loss: 0.5395 - accuracy: 0.7371\n",
      "Epoch 00045: saving model to training\\cp-0045.ckpt\n",
      "623/804 [======================>.......] - ETA: 0s - loss: 0.5408 - accuracy: 0.7370\n",
      "Epoch 00045: saving model to training\\cp-0045.ckpt\n",
      "750/804 [==========================>...] - ETA: 0s - loss: 0.5404 - accuracy: 0.7371\n",
      "Epoch 00045: saving model to training\\cp-0045.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7376 - val_loss: 0.6924 - val_accuracy: 0.5254\n",
      "Epoch 46/50\n",
      "114/804 [===>..........................] - ETA: 0s - loss: 0.5509 - accuracy: 0.7275\n",
      "Epoch 00046: saving model to training\\cp-0046.ckpt\n",
      "247/804 [========>.....................] - ETA: 0s - loss: 0.5435 - accuracy: 0.7351\n",
      "Epoch 00046: saving model to training\\cp-0046.ckpt\n",
      "404/804 [==============>...............] - ETA: 0s - loss: 0.5415 - accuracy: 0.7370\n",
      "Epoch 00046: saving model to training\\cp-0046.ckpt\n",
      "613/804 [=====================>........] - ETA: 0s - loss: 0.5381 - accuracy: 0.7386\n",
      "Epoch 00046: saving model to training\\cp-0046.ckpt\n",
      "740/804 [==========================>...] - ETA: 0s - loss: 0.5384 - accuracy: 0.7387\n",
      "Epoch 00046: saving model to training\\cp-0046.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7377 - val_loss: 0.7663 - val_accuracy: 0.4746\n",
      "Epoch 47/50\n",
      "104/804 [==>...........................] - ETA: 0s - loss: 0.5417 - accuracy: 0.7341\n",
      "Epoch 00047: saving model to training\\cp-0047.ckpt\n",
      "255/804 [========>.....................] - ETA: 0s - loss: 0.5405 - accuracy: 0.7336\n",
      "Epoch 00047: saving model to training\\cp-0047.ckpt\n",
      "453/804 [===============>..............] - ETA: 0s - loss: 0.5399 - accuracy: 0.7345\n",
      "Epoch 00047: saving model to training\\cp-0047.ckpt\n",
      "576/804 [====================>.........] - ETA: 0s - loss: 0.5372 - accuracy: 0.7374\n",
      "Epoch 00047: saving model to training\\cp-0047.ckpt\n",
      "761/804 [===========================>..] - ETA: 0s - loss: 0.5374 - accuracy: 0.7382\n",
      "Epoch 00047: saving model to training\\cp-0047.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5383 - accuracy: 0.7375 - val_loss: 0.7808 - val_accuracy: 0.4746\n",
      "Epoch 48/50\n",
      "109/804 [===>..........................] - ETA: 0s - loss: 0.5378 - accuracy: 0.7380\n",
      "Epoch 00048: saving model to training\\cp-0048.ckpt\n",
      "274/804 [=========>....................] - ETA: 0s - loss: 0.5385 - accuracy: 0.7391\n",
      "Epoch 00048: saving model to training\\cp-0048.ckpt\n",
      "434/804 [===============>..............] - ETA: 0s - loss: 0.5368 - accuracy: 0.7363\n",
      "Epoch 00048: saving model to training\\cp-0048.ckpt\n",
      "610/804 [=====================>........] - ETA: 0s - loss: 0.5391 - accuracy: 0.7358\n",
      "Epoch 00048: saving model to training\\cp-0048.ckpt\n",
      "737/804 [==========================>...] - ETA: 0s - loss: 0.5402 - accuracy: 0.7356\n",
      "Epoch 00048: saving model to training\\cp-0048.ckpt\n",
      "804/804 [==============================] - 1s 2ms/step - loss: 0.5385 - accuracy: 0.7375 - val_loss: 0.8090 - val_accuracy: 0.4746\n",
      "Epoch 49/50\n",
      "115/804 [===>..........................] - ETA: 0s - loss: 0.5411 - accuracy: 0.7340\n",
      "Epoch 00049: saving model to training\\cp-0049.ckpt\n",
      "260/804 [========>.....................] - ETA: 0s - loss: 0.5399 - accuracy: 0.7322\n",
      "Epoch 00049: saving model to training\\cp-0049.ckpt\n",
      "411/804 [==============>...............] - ETA: 0s - loss: 0.5360 - accuracy: 0.7381\n",
      "Epoch 00049: saving model to training\\cp-0049.ckpt\n",
      "607/804 [=====================>........] - ETA: 0s - loss: 0.5390 - accuracy: 0.7359\n",
      "Epoch 00049: saving model to training\\cp-0049.ckpt\n",
      "747/804 [==========================>...] - ETA: 0s - loss: 0.5378 - accuracy: 0.7368\n",
      "Epoch 00049: saving model to training\\cp-0049.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7367 - val_loss: 0.7507 - val_accuracy: 0.4746\n",
      "Epoch 50/50\n",
      "106/804 [==>...........................] - ETA: 0s - loss: 0.5467 - accuracy: 0.7338\n",
      "Epoch 00050: saving model to training\\cp-0050.ckpt\n",
      "250/804 [========>.....................] - ETA: 0s - loss: 0.5340 - accuracy: 0.7431\n",
      "Epoch 00050: saving model to training\\cp-0050.ckpt\n",
      "387/804 [=============>................] - ETA: 0s - loss: 0.5376 - accuracy: 0.7400\n",
      "Epoch 00050: saving model to training\\cp-0050.ckpt\n",
      "596/804 [=====================>........] - ETA: 0s - loss: 0.5387 - accuracy: 0.7371\n",
      "Epoch 00050: saving model to training\\cp-0050.ckpt\n",
      "721/804 [=========================>....] - ETA: 0s - loss: 0.5384 - accuracy: 0.7371\n",
      "Epoch 00050: saving model to training\\cp-0050.ckpt\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7369 - val_loss: 0.7564 - val_accuracy: 0.4746\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Include the epoch in the file name (uses `str.format`)\n",
    "checkpoint_path = \"training/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                 save_weights_only=True, \n",
    "                                                 save_freq = 5*batch_size, \n",
    "                                                 verbose=1)\n",
    "\n",
    "# Save the weights using the `checkpoint_path` format\n",
    "nn_model.save_weights(checkpoint_path.format(epoch=0))\n",
    "\n",
    "# Train the model with the new callback\n",
    "fit_model = nn_model.fit(X_train_scaled, y_train, epochs=50, \n",
    "                         batch_size=batch_size,\n",
    "                        validation_data=(X_test, y_test), callbacks=[cp_callback], verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5477 - accuracy: 0.7355 - 367ms/epoch - 1ms/step\n",
      "Loss: 0.5477002859115601, Accuracy: 0.7355102300643921\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn_model.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "\n",
    "nn_model.save('../Resources/AlphabetSoupCharity.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(fit_model.history)\n",
    "\n",
    "history_df.index += 1\n",
    "\n",
    "history_df.plot(y='loss', color = 'red')\n",
    "plt.xlabel('Epoch Index')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Graph')\n",
    "plt.legend (loc = 'center right')\n",
    "plt.savefig(\"../Images/Model_Loss.png\")\n",
    "\n",
    "\n",
    "history_df.plot(y='accuracy', color = 'green')\n",
    "plt.xlabel('Epoch Index')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Accuracy Graph')\n",
    "plt.legend (loc = 'center right')\n",
    "plt.savefig(\"../Images/Model_Accuracy.png\")\n",
    "\n",
    "\n",
    "plt.figure(figsize = (15,5))\n",
    "plt.plot(history_df['loss'], color='red', label='loss', )\n",
    "plt.plot(history_df['accuracy'], color='green', label='accuracy')\n",
    "plt.xlim([0, 52])\n",
    "plt.ylim([0.45, 0.8])\n",
    "plt.xlabel('Epoch Index')\n",
    "plt.ylabel('Accuracy/Loss')\n",
    "plt.title('Model Training Accuracy/Loss Graph')\n",
    "plt.legend(loc = 'center right')\n",
    "plt.savefig(\"../Images/ModelAccuracy_Loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
